# agentes/prompts.py

BASE_PROMPT = """\
Tu tarea es responder exclusivamente en formato JSON v谩lido y sin explicaciones adicionales. 
No incluyas texto antes ni despu茅s del bloque JSON. 
Asegurate de que sea un JSON parseable por una m谩quina. 
"""

def prompt_arquitecto(objetivo, contexto="", temperatura=0.2, modelo="codellama:7b-instruct"):
    full_prompt = f"""{BASE_PROMPT}
Objetivo: {objetivo}
{f'Contexto: {contexto}' if contexto else ''}

Devolveme una lista de tareas en formato JSON con los siguientes campos:
- tarea: descripci贸n corta de la acci贸n
- tipo: ['investigaci贸n', 'redacci贸n', 'configuraci贸n', etc.]
- prioridad: n煤mero del 1 (alta) al 5 (baja)
- depende_de: lista de otras tareas si aplica
- actor: "usuario" o "asistente" seg煤n quien debe ejecutar la tarea

Ejemplo de salida:
[
  {{
    "tarea": "Definir requerimientos iniciales",
    "tipo": "investigaci贸n",
    "prioridad": 1,
    "depende_de": [],
    "actor": "usuario"
  }},
  {{
    "tarea": "Prototipar soluci贸n propuesta",
    "tipo": "programaci贸n",
    "prioridad": 2,
    "depende_de": ["Definir requerimientos iniciales"],
    "actor": "asistente"
  }}
]

"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }



def prompt_codigo(prompt_usuario, temperatura=0.2, modelo="codellama:7b-instruct"):
    prompt = (
        "Respond茅 solo con el c贸digo, en formato JSON si es posible. "
        "No expliques nada. No incluyas encabezados ni texto fuera del bloque de c贸digo.\n"
        f"INSTRUCCIN: {prompt_usuario}"
    )
    return {
        "model": modelo,
        "prompt": prompt,
        "temperature": temperatura,
        "stream": False
    }


def prompt_constructor(objetivo, contexto="", temperatura=0.2, modelo="phind-codellama"):
    full_prompt = f"""{BASE_PROMPT}
Analiz谩 el siguiente objetivo: "{objetivo}"
{f'Contexto: {contexto}' if contexto else ''}

Devuelve una lista JSON de tareas necesarias para cumplirlo. 
Cada tarea debe tener: id, descripcion, prioridad (alta/media/baja).

Formato esperado:
[
  {{
    "id": 1,
    "descripcion": "Inicializar repositorio git",
    "prioridad": "alta"
  }},
  ...
]"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }

def prompt_evaluacion(texto, criterio="calidad t茅cnica", temperatura=0.2, modelo="phind-codellama"):
    full_prompt = f"""{BASE_PROMPT}
Evalu谩 el siguiente texto seg煤n el criterio '{criterio}'.

Texto:
{texto}

Formato esperado:
{{
  "criterio": "{criterio}",
  "calificacion": <n煤mero del 1 al 10>,
  "justificacion": "<breve justificaci贸n>"
}}"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }

#  Extra: para casos de metadata, info estructurada, etc.
def prompt_info(categoria, temperatura=0.2, modelo="phind-codellama"):
    full_prompt = f"""{BASE_PROMPT}
Devolveme informaci贸n relevante sobre la categor铆a "{categoria}" en formato JSON.

Formato esperado:
{{
  "categoria": "{categoria}",
  "datos": [
    "...",
    "..."
  ]
}}"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }